{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f90369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import itertools\n",
    "from typing import Union, Tuple, Iterable\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de2738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "data_root_path = Path('/eagle/projects/candle_aesp/siebenschuh/PT/')\n",
    "\n",
    "# input\n",
    "# - pre-processing\n",
    "# - rotation\n",
    "absDeg = 5\n",
    "# - horizontal flip\n",
    "p_hFlip = 0.2\n",
    "# model\n",
    "# - optimizer\n",
    "b_size     = 512\n",
    "opt        = 'Adam'\n",
    "l_rate     = 0.001\n",
    "moment     = 0.2\n",
    "n_epochs   = 12\n",
    "# # of workers\n",
    "n_workers  = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a63ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputDim(inputDim:Tuple[int], nClasses:int, cnn_channels:Iterable[int], cnn_kernels, pool_kernels, cnn_pad):\n",
    "    '''Computes image shape post convolution/pooling/batchnorm layers\n",
    "    Input image (C, H, W) --> CNN output tensor (C, H, W)\n",
    "    '''\n",
    "    \n",
    "    assert len(inputDim)==3, \"inputDim must have exactly 3 int entries (C,H,W)\"\n",
    "    c, h, w = inputDim\n",
    "    \n",
    "    def dim_out(f, k, k_p, p):\n",
    "        return ((f-k+1 + 2*p) // k_p) \n",
    "    \n",
    "    w_loc, h_loc = w, h\n",
    "    for k, k_p, p in zip(cnn_kernels, pool_kernels, cnn_pad):\n",
    "        h_loc, w_loc = dim_out(h_loc, k, k_p, p), dim_out(w_loc, k, k_p, p)\n",
    "    \n",
    "    return cnn_channels[-1], w_loc, h_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8a586c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load & pre-process data\n",
    "# - - - - - - - - - - - -\n",
    "# - transformation\n",
    "TraFo = transforms.Compose(transforms=[\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.RandomRotation((-1.*absDeg, absDeg)),\n",
    "    transforms.RandomHorizontalFlip(p_hFlip)\n",
    "])\n",
    "\n",
    "# - load data\n",
    "dset_train = torchvision.datasets.CIFAR10(root=data_root_path, train=True, download=True, transform=TraFo)\n",
    "dset_test  = torchvision.datasets.CIFAR10(root=data_root_path, train=False, download=True, transform=TraFo)\n",
    "\n",
    "# - input dimension\n",
    "inputDim = tuple(dset_train[0][0].shape)\n",
    "\n",
    "# - preprocess\n",
    "loader_train = DataLoader(dataset=dset_train, batch_size=b_size, shuffle=True, num_workers=n_workers, pin_memory=True)\n",
    "loader_test  = DataLoader(dataset=dset_test, batch_size=b_size, shuffle=True,  num_workers=n_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "467fa13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model helpers\n",
    "def conv_block(in_c, out_c, p, k_cnn, k_pool, *args, **kwargs):\n",
    "    return nn.Sequential(nn.Conv2d(in_c, out_c, kernel_size = k_cnn, padding=p, *args, **kwargs),\n",
    "                         nn.BatchNorm2d(out_c),\n",
    "                         nn.MaxPool2d(k_pool),\n",
    "                         nn.ReLU())\n",
    "\n",
    "def downsample(in_c:int, bias:bool=False):\n",
    "    '''\n",
    "    Downsampling \n",
    "    '''\n",
    "    return nn.Sequential(nn.Conv2d(in_c, 2*in_c, kernel_size=1, stride=2, padding=0, bias=bias),\n",
    "                         nn.BatchNorm2d(2*in_c))\n",
    "    \n",
    "def basic_block(in_c:int, upscale:bool, stride:int, bias:bool=False, *args, **kwargs):\n",
    "    '''\n",
    "    Residual NN block with standard 3x3 convolutions (projection via convolution layer to maintain dimension of input)\n",
    "    '''\n",
    "    if(upscale):\n",
    "        out_c = 2*in_c\n",
    "    else:\n",
    "        out_c = in_c\n",
    "    return nn.Sequential(nn.Conv2d(in_c, out_c, kernel_size=3, stride=stride, padding=1, bias=bias),\n",
    "                         nn.BatchNorm2d(out_c),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "                         nn.BatchNorm2d(out_c))\n",
    "\n",
    "def resnet_layer(in_c:int, downsampleFlag:bool=True, bias:bool=False, *args, **kwargs):\n",
    "    '''\n",
    "    Singular ResNet-layer (downsampling variant)\n",
    "    '''\n",
    "    \n",
    "    if(downsampleFlag):\n",
    "        return nn.Sequential(*[basic_block(in_c=in_c, upscale=True, stride=2, bias=bias, *args, **kwargs), \n",
    "                               downsample(in_c=in_c, bias=bias),\n",
    "                               basic_block(in_c=2*in_c, upscale=False, stride=1, bias=bias, *args, **kwargs)])\n",
    "    else:\n",
    "        return nn.Sequential(*[basic_block(in_c=in_c, upscale=False, stride=1, bias=bias, *args, **kwargs), \n",
    "                               basic_block(in_c=in_c, upscale=False, stride=1, bias=bias, *args, **kwargs)])\n",
    "\n",
    "def res_resizing_block(in_c, *args, **kwargs):\n",
    "    '''\n",
    "    Residual NN block with standard 3x3 convolutions (projection via convolution layer to maintain dimension of input)\n",
    "    '''\n",
    "    return nn.Sequential(nn.Conv2d(in_c, 2*in_c, kernel_size=3, stride = 2, padding = 1),\n",
    "                         nn.BatchNorm2d(2*in_c),\n",
    "                         nn.ReLU())\n",
    "\n",
    "def fc_block(in_f, out_f, pDrop=0.05, lastLayerFlag:bool=False, *args, **kwargs):\n",
    "    # last layer\n",
    "    if(lastLayerFlag):\n",
    "        return nn.Sequential(nn.Linear(in_f, out_f, *args, **kwargs))\n",
    "    \n",
    "    return nn.Sequential(nn.Linear(in_f, out_f, *args, **kwargs),\n",
    "                         nn.Dropout(pDrop),\n",
    "                         nn.ReLU())\n",
    "\n",
    "# model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 cnn_channels:Iterable[int], \n",
    "                 fc_channels:Iterable[int], \n",
    "                 cnn_kernels:int|Iterable[int],\n",
    "                 inputDim:tuple, \n",
    "                 nClasses:int,\n",
    "                 pool_kernels:int|Iterable[int]=2,\n",
    "                 cnn_pad:int|Iterable[int]=0,\n",
    "                 pDrop:float=0.05):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_channels  = cnn_channels\n",
    "        self.fc_channels   = fc_channels\n",
    "        self.cnn_kernels   = cnn_kernels\n",
    "        self.inputDim      = inputDim\n",
    "        self.nClasses      = nClasses\n",
    "        self.pool_kernels  = pool_kernels\n",
    "        self.cnn_pad       = cnn_pad\n",
    "        self.pDrop         = pDrop\n",
    "        \n",
    "        # convert input\n",
    "        cnn_depth = len(self.cnn_channels)\n",
    "        if(isinstance(self.cnn_kernels, int)):\n",
    "            self.cnn_kernels = [self.cnn_kernels]*cnn_depth\n",
    "        if(isinstance(self.pool_kernels, int)):\n",
    "            self.pool_kernels = [self.pool_kernels]*cnn_depth\n",
    "        if(isinstance(self.cnn_pad, int)):\n",
    "            self.cnn_pad = [self.cnn_pad]*cnn_depth\n",
    "        \n",
    "        # CNN\n",
    "        cnn_channels_aug = [inputDim[0]] + cnn_channels\n",
    "        conv_blocks = [conv_block(in_c, out_c, p, k_cnn, k_pool,) for (in_c, out_c, p, k_cnn, k_pool) in zip(cnn_channels_aug, cnn_channels_aug[1:], self.cnn_pad, self.cnn_kernels, self.pool_kernels)]\n",
    "        self.conv = nn.Sequential(*conv_blocks)\n",
    "\n",
    "        # intermediate dimension\n",
    "        x_dim = getOutputDim(self.inputDim, nClasses=self.nClasses, cnn_channels=self.cnn_channels, \n",
    "                             cnn_kernels=self.cnn_kernels, pool_kernels=self.pool_kernels, \n",
    "                             cnn_pad=self.cnn_pad)\n",
    "        feat_in  = np.prod(x_dim)\n",
    "\n",
    "        # FC\n",
    "        if(len(fc_channels) > 0):\n",
    "            fc_channels_aug = [feat_in]+fc_channels+[self.nClasses]\n",
    "        else:\n",
    "            fc_channels_aug = [feat_in]+[self.nClasses]\n",
    "        fc_blocks = [fc_block(in_f, out_f, lastLayerFlag=j==len(fc_channels_aug)-2) for j, (in_f, out_f) in enumerate(zip(fc_channels_aug, fc_channels_aug[1:]))]\n",
    "        self.fc = nn.Sequential(*fc_blocks)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN\n",
    "        x = self.conv(x)\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1) # flat\n",
    "        \n",
    "        # FC\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 depth:int,\n",
    "                 nClasses:int,\n",
    "                 inputDim:Tuple[int]):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.depth    = depth\n",
    "        self.nClasses = nClasses\n",
    "        self.inputDim = inputDim\n",
    "\n",
    "        # residual CNN blocks\n",
    "        conv_blocks = list(itertools.chain(*[[res_proj_block(64*2**(d))]+[res_resizing_block(64*2**(d))] for d in range(depth)]))\n",
    "        c0 = nn.Sequential(*[nn.Conv2d(3, 64, kernel_size=3, stride=1)])\n",
    "        c1 = nn.Sequential(*conv_blocks)\n",
    "        # avg pooling\n",
    "        p1 = nn.Sequential(nn.AdaptiveAvgPool2d(output_size=(1,1)))\n",
    "        self.conv = nn.Sequential(*[c0, c1, p1])\n",
    "\n",
    "        # intermediate dimension\n",
    "        x_dim = self.conv(torch.zeros((1, *inputDim))).shape\n",
    "        self.feat_in = np.prod(x_dim)\n",
    "\n",
    "        # FC\n",
    "        self.fc = nn.Sequential(nn.Linear(self.feat_in, self.nClasses))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN\n",
    "        x = self.conv(x)\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1) # flat\n",
    "        \n",
    "        # FC\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e34e458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 8, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nn.Sequential(*[basic_block(in_c=in_c, upscale=True, stride=2, bias=bias, *args, **kwargs), \n",
    "#                           downsample(in_c=in_c, bias=bias),\n",
    "#                           basic_block(in_c=2*in_c, upscale=False, stride=1, bias=bias, *args, **kwargs)])\n",
    "\n",
    "x = torch.rand((16, 32, 32, 32))\n",
    "\n",
    "l1 = basic_block(in_c=32, upscale=False, stride=2)\n",
    "l2 = basic_block(in_c=32, upscale=False, stride=2)\n",
    "#ds = downsample(in_c=6, bias=False)\n",
    "l2(l1(x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "350bbdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((16, 3,32,32))\n",
    "layer = resnet_layer(in_c=3, downsampleFlag=False)\n",
    "layer(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc6caca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = resnet_layer(in_c=64, downsampleFlag=True)\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model\n",
    "net = ResNet(depth = 4, nClasses=10, inputDim=(3,32,32))\n",
    "\n",
    "# -> GPU\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91efbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.feat_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e13233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model Inputs\n",
    "inputDim = (3, 32, 32)\n",
    "\n",
    "# Inputs\n",
    "cnn_channels:Iterable[int]    = [8,   32, 64, 128, 256]\n",
    "fc_channels:Iterable[int]     = [512, 256, 128]\n",
    "cnn_kernels:int|Iterable[int] = [3, 3, 2, 2, 2, 2]\n",
    "cnn_pad:int|Iterable[int]     = 2\n",
    "nClasses:int                  = 10\n",
    "\n",
    "# Model\n",
    "net = NN(cnn_channels = cnn_channels, \n",
    "         fc_channels = fc_channels, \n",
    "         cnn_kernels  = cnn_kernels, \n",
    "         cnn_pad      = cnn_pad,\n",
    "         pDrop        = 0.075, \n",
    "         inputDim     = inputDim, \n",
    "         nClasses     = 10)\n",
    "\n",
    "# -> GPU\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3465ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.00001, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Metric\n",
    "accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
    "accuracy = accuracy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31741074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "acc = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
    "\n",
    "# \n",
    "acc_local    = 0.0\n",
    "running_loss = 0.0\n",
    "loss_list    = []\n",
    "train_acc, test_acc = [], []\n",
    "\n",
    "# 1st loop: epochs\n",
    "for i in range(100):\n",
    "    print(f'\\nEpoch: {i}')\n",
    "    \n",
    "    # 2nd loop: train batches\n",
    "    for j, batch in enumerate(loader_train):\n",
    "        # unpack\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        # -> device 13s\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backprop\n",
    "        outputs = net(inputs)                  # forward\n",
    "        loss    = criterion(outputs, labels)   # loss\n",
    "        loss.backward()                        # backward \n",
    "        optimizer.step()\n",
    "        \n",
    "        # loss\n",
    "        running_loss += loss.item()\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        # print\n",
    "        if(j%100==99):\n",
    "            print(f'Loss : {loss:.2f}')\n",
    "            \n",
    "    # track\n",
    "    train_acc.append(acc(outputs.argmax(dim=1).cpu(), labels.cpu()))\n",
    "    \n",
    "    \n",
    "    # validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        test_acc_loc = []\n",
    "        for batch in loader_test:\n",
    "            inputs, labels = batch\n",
    "            \n",
    "            # -> device 13s\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # predict\n",
    "            preds = net(inputs).argmax(dim=1)\n",
    "    \n",
    "            # accuracy\n",
    "            test_acc_loc.append(acc(preds.cpu(), labels.cpu()))\n",
    "        # append\n",
    "        test_acc.append(np.mean(test_acc_loc))\n",
    "\n",
    "print('\\nFinished\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81132df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0729f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c659560",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68779529",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199621f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30931a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c79c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad784d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10\n",
    "# net = NN(cnn_depth=3, cnn_k=3, fc_depth=3, cnn_mult=4, pDrop=0.075, inputDim=inputDim, nClasses=10)\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3095d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e1baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "diff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
