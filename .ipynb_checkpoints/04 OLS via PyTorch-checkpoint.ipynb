{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d460fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "\n",
    "n        = 1024\n",
    "b_size   = 1\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPointCloud(n:int, k:int, k_eff:int, vola:float=0.3, seedVal:int=5493) -> pd.DataFrame:\n",
    "    '''\n",
    "    creates dataset\n",
    "    '''\n",
    "\n",
    "    assert k>=k_eff, \"Dimension `k` must be bigger than effective dimension `k_eff`.\"\n",
    "    assert vola >= 0.0, \"Error vola must be non-negative.\"\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(seedVal)\n",
    "    \n",
    "    # get data\n",
    "    X         = np.random.normal(0, 1, n*k).reshape(n, -1)\n",
    "    id_eff    = np.random.choice(a=range(X.shape[1]), size=k_eff, replace=False)\n",
    "\n",
    "    # beta\n",
    "    beta      = np.random.normal(0, 4, X.shape[1]).round(3)\n",
    "    beta[[i for i in range(len(beta)) if i not in id_eff]] = 0.\n",
    "    \n",
    "    # debug\n",
    "    beta     = np.zeros_like(beta)\n",
    "    beta[1] = -2\n",
    "    beta[3] = 1.5\n",
    "    beta[7] = 4\n",
    "\n",
    "    # response : `y`\n",
    "    y = X@beta \n",
    "    y += np.random.normal(loc=0, scale=vola, size=y.shape)\n",
    "    \n",
    "    outDict = {'y' : y}\n",
    "    outDict.update( {f'x_{i}' : x for i, x in enumerate(X.T, start=1)})\n",
    "    \n",
    "    return pd.DataFrame(outDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pointCloud(Dataset):\n",
    "    \n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        self.dataframe = df\n",
    "        self.DF = df.to_numpy()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        assert idx in range(self.__len__())\n",
    "        return self.DF[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "\n",
    "# sample data\n",
    "k, k_eff = 15, 5\n",
    "df = createPointCloud(n, k, k_eff)\n",
    "\n",
    "# ...Dataset\n",
    "dset_train = pointCloud(df.iloc[:round(0.8*len(df))])\n",
    "dset_test  = pointCloud(df.iloc[round(0.8*len(df)):])\n",
    "\n",
    "# ...Dataloader\n",
    "trainloader = DataLoader(dataset=dset_train, batch_size = b_size, num_workers=1, pin_memory=True)\n",
    "testloader  = DataLoader(dataset=dset_test,  batch_size = len(dset_test), num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8740a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LinMod(nn.Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin     = nn.Linear(in_features=k, out_features=1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x[:,0]\n",
    "    \n",
    "    def eval(self,):\n",
    "        self.coef_ = list(self.parameters())[0].data.numpy()[0]\n",
    "        \n",
    "\n",
    "\n",
    "# create instance \n",
    "lm1 = LinMod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ddda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer, criterion\n",
    "criterion = nn.MSELoss() # L1Loss\n",
    "optimizer = optim.SGD(params=lm1.parameters(), lr=0.001, weight_decay=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "\n",
    "# epoch loop\n",
    "for i in range(n_epochs):\n",
    "    print('Epoch : ', i+1)\n",
    "    # batch loop\n",
    "    for j,b in enumerate(trainloader):\n",
    "        y, x = b[:,0].type(torch.float), b[:,1:].type(torch.float)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_hat = lm1(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if j % 512 == 511:    # print every 2000 mini-batches\n",
    "            print(f'[{i + 1}, {i + 1:2d}] loss: {running_loss / 5:.4f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print('Training: Done.')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b in testloader:\n",
    "        y, x = b[:,0].type(torch.float), b[:,1:].type(torch.float)\n",
    "        y_hat_test = lm1(x)\n",
    "        y_test = y\n",
    "        \n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2cfc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute test accuracy\n",
    "mse = torchmetrics.MeanSquaredError()\n",
    "mse(y_test, y_hat_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually assess parameter estimates\n",
    "lm1.eval()\n",
    "lm1.coef_.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "diff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
